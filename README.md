# MLOps Churn Prediction Pipeline

An end-to-end MLOps pipeline for customer churn prediction with automated training, deployment, monitoring, and production-ready serving capabilities.

## ğŸ¯ Overview

This project implements a complete machine learning operations (MLOps) pipeline for predicting customer churn using multiple algorithms and industry best practices. The pipeline includes data processing, model training, hyperparameter optimization, model deployment, and continuous monitoring.

### Key Features

- **Multi-Model Support**: XGBoost, LightGBM, Random Forest, Logistic Regression, SVM, and Ensemble methods
- **Experiment Tracking**: MLflow integration for comprehensive experiment management
- **Pipeline Orchestration**: ZenML for reproducible and scalable ML pipelines
- **Hyperparameter Optimization**: Optuna integration for automated tuning
- **Model Deployment**: FastAPI-based REST API with automatic model serving
- **Interactive Dashboard**: Streamlit application for real-time predictions and monitoring
- **Data Drift Monitoring**: Evidently AI integration for production monitoring
- **Containerization**: Docker and Kubernetes manifests for cloud deployment
- **CI/CD Ready**: Automated testing, validation, and deployment pipelines

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Data Ingestionâ”‚    â”‚  Feature        â”‚    â”‚   Model         â”‚
â”‚   & Validation  â”‚â”€â”€â”€â–¶â”‚  Engineering    â”‚â”€â”€â”€â–¶â”‚   Training      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Model         â”‚    â”‚   API Serving   â”‚    â”‚   Monitoring    â”‚
â”‚   Registry      â”‚    â”‚   (FastAPI)     â”‚    â”‚   & Alerts      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```
![Churn Architecture](https://github.com/MYasvanth/mlops_churn_prediction/blob/master/Churn_Architecture.png)
## ğŸ“Š Model Performance

| Model | Accuracy | Precision | Recall | F1-Score |
|-------|----------|-----------|--------|----------|
| XGBoost | 80.4% | 0.82 | 0.79 | 0.80 |
| LightGBM | 80.1% | 0.81 | 0.78 | 0.79 |
| Random Forest | 79.8% | 0.80 | 0.77 | 0.78 |
| Logistic Regression | 79.2% | 0.79 | 0.76 | 0.77 |



### Running the Pipeline

1. **Train models**
   ```bash
   python run_churn_pipeline.py --model-type xgboost --hyperparameter-optimization
   ```

2. **Start the API server**
   ```bash
   python scripts/monitoring/run_fastapi_server.py
   ```

3. **Launch the dashboard**
   ```bash
   streamlit run src/deployment/streamlit_app.py --server.port 8501
   ```

4. **View experiment tracking**
   ```bash
   mlflow ui --port 5000
   ```

## ğŸ“– Usage

### Training Pipeline

```bash
# Basic training
python run_churn_pipeline.py --model-type xgboost

# With hyperparameter optimization
python run_churn_pipeline.py --model-type lightgbm --hyperparameter-optimization --n-trials 100

# Deploy to production
python run_churn_pipeline.py --model-type xgboost --deploy-to-production
```

### API Endpoints

The FastAPI server provides the following endpoints:

- `GET /health` - Health check
- `GET /models` - List available models
- `POST /predict` - Make predictions
- `GET /monitoring/metrics` - Get monitoring metrics

### Example Prediction Request

```bash
curl -X POST "http://localhost:8000/predict" \
     -H "Content-Type: application/json" \
     -d '{
       "gender": "Female",
       "SeniorCitizen": 0,
       "Partner": "Yes",
       "Dependents": "No",
       "tenure": 12,
       "PhoneService": "Yes",
       "MultipleLines": "No",
       "InternetService": "Fiber optic",
       "OnlineSecurity": "No",
       "OnlineBackup": "Yes",
       "DeviceProtection": "No",
       "TechSupport": "No",
       "StreamingTV": "Yes",
       "StreamingMovies": "No",
       "Contract": "Month-to-month",
       "PaperlessBilling": "Yes",
       "PaymentMethod": "Electronic check",
       "MonthlyCharges": 85.5,
       "TotalCharges": 1023.75
     }'
```

## ğŸ›ï¸ Project Structure

```
mlops_churn_prediction/
â”œâ”€â”€ configs/                 # Configuration files
â”‚   â”œâ”€â”€ data/               # Data processing configs
â”‚   â”œâ”€â”€ deployment/         # Deployment configurations
â”‚   â”œâ”€â”€ model/              # Model hyperparameters
â”‚   â””â”€â”€ monitoring/         # Monitoring settings
â”œâ”€â”€ data/                   # Data directory
â”‚   â”œâ”€â”€ raw/               # Raw data
â”‚   â”œâ”€â”€ processed/         # Processed data
â”‚   â””â”€â”€ external/          # External data sources
â”œâ”€â”€ deployment/             # Deployment configurations
â”‚   â”œâ”€â”€ docker/            # Docker files
â”‚   â”œâ”€â”€ kubernetes/        # K8s manifests
â”‚   â””â”€â”€ cloud/             # Cloud deployment configs
â”œâ”€â”€ models/                 # Trained models
â”‚   â”œâ”€â”€ staging/           # Staging models
â”‚   â””â”€â”€ production/        # Production models
â”œâ”€â”€ monitoring/             # Monitoring components
â”‚   â”œâ”€â”€ alerts/            # Alert configurations
â”‚   â”œâ”€â”€ dashboards/        # Monitoring dashboards
â”‚   â””â”€â”€ logs/              # Application logs
â”œâ”€â”€ notebooks/              # Jupyter notebooks
â”œâ”€â”€ reports/                # Generated reports
â”‚   â”œâ”€â”€ drift_reports/     # Data drift reports
â”‚   â””â”€â”€ performance_reports/ # Model performance reports
â”œâ”€â”€ scripts/                # Utility scripts
â”œâ”€â”€ src/                    # Source code
â”‚   â”œâ”€â”€ data/              # Data processing modules
â”‚   â”œâ”€â”€ features/          # Feature engineering
â”‚   â”œâ”€â”€ models/            # Model training modules
â”‚   â”œâ”€â”€ deployment/        # Deployment modules
â”‚   â”œâ”€â”€ monitoring/        # Monitoring modules
â”‚   â””â”€â”€ pipelines/         # ML pipelines
â”œâ”€â”€ tests/                  # Test suites
â”œâ”€â”€ zenml_pipelines/        # ZenML pipeline definitions
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ setup.py               # Package setup
â”œâ”€â”€ dvc.yaml              # Data version control
â””â”€â”€ README.md             # Project documentation
```


## ğŸ“ˆ Monitoring & Observability

### Data Drift Detection

```bash
# Run drift detection
python scripts/monitoring/run_data_drift_monitor.py

# View drift reports
ls reports/drift_reports/
```

### Performance Monitoring

- **MLflow UI**: http://localhost:5000
- **Streamlit Dashboard**: http://localhost:8501
- **Optuna Dashboard**: http://localhost:8080
- **API Documentation**: http://localhost:8000/docs

## ğŸ§ª Testing

Run the test suite:

```bash
# Run all tests
pytest tests/

# Run specific test module
pytest tests/test_models/

# Run with coverage
pytest --cov=src --cov-report=html
```


## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

